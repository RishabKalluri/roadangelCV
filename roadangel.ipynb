{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63be30c-0ef2-45ce-b395-ae4e854d3b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mediapipe\n",
      "Version: 0.10.18\n",
      "Summary: MediaPipe is the simplest way for researchers and developers to build world-class ML solutions and applications for mobile, edge, cloud and the web.\n",
      "Home-page: https://github.com/google/mediapipe\n",
      "Author: The MediaPipe Authors\n",
      "Author-email: mediapipe@google.com\n",
      "License: Apache 2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
      "Requires: absl-py, attrs, flatbuffers, jax, jaxlib, matplotlib, numpy, opencv-contrib-python, protobuf, sentencepiece, sounddevice\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8457e677-d346-4e1c-9f86-237aef0e530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e658a0a-a117-45c5-a1ed-bc793002a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09f4d65-7002-469e-9d59-596cef2d0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Mesh and Drawing Utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=(0, 255, 0))\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "def getLandmarks(image, face_mesh):\n",
    "    \"\"\"\n",
    "    Detects face landmarks in an image and calculates relative coordinates.\n",
    "    \"\"\"\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    #image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    \n",
    "    landmarks = []\n",
    "    relative_landmarks = []\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face in results.multi_face_landmarks:\n",
    "            for landmark in face.landmark:\n",
    "                x = landmark.x\n",
    "                y = landmark.y\n",
    "                \n",
    "                # Convert normalized coordinates to image pixels\n",
    "                shape = image.shape\n",
    "                relative_x = int(x * shape[1])  # shape[1] is the width\n",
    "                relative_y = int(y * shape[0])  # shape[0] is the height\n",
    "                relative_landmarks.append((relative_x, relative_y))\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "    return landmarks, relative_landmarks, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b88c28-ccca-420a-a8cd-b3bb1d3f2ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1732740496.203331 8827564 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2\n",
      "W0000 00:00:1732740496.207499 8899349 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1732740496.221738 8899348 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(1)  # Use 0 for the default camera, or 1 for external cameras\n",
    "    cap.set(3, 640)  # Set width\n",
    "    cap.set(4, 420)  # Set height\n",
    "    cap.set(10, 100)  # Set brightness\n",
    "\n",
    "    # Initialize FaceMesh model\n",
    "    face_mesh = mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,  # Enables iris landmarks\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        # Capture webcam frames\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print('Ignoring empty camera frame.')\n",
    "            continue\n",
    "\n",
    "        # Flip the frame horizontally and convert BGR to RGB\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get landmarks and results\n",
    "        #landmarks, results = getLandmarks(rgb_frame, face_mesh)\n",
    "        landmarks, relative_landmarks, results = getLandmarks(rgb_frame, face_mesh)\n",
    "\n",
    "        frame_output = frame.copy()\n",
    "        #Get eye positions\n",
    "        if len(landmarks) > 0:\n",
    "            rightEyeImg = getRightEye(frame_output, landmarks)\n",
    "            rightEyeHeight, rightEyeWidth, _ = rightEyeImg.shape\n",
    "            \n",
    "            xRightEye, yRightEye, rightEyeWidth, rightEyeHeight = getRightEyeRect(frame_output, landmarks)\n",
    "            cv2.rectangle(frame_output, (xRightEye, yRightEye),\n",
    "                          (xRightEye + rightEyeWidth, yRightEye + rightEyeHeight), (200, 21, 36), 2)\n",
    "            \n",
    "            # LEFT EYE\n",
    "            leftEyeImg = getLeftEye(frame_output, landmarks)\n",
    "            leftEyeHeight, leftEyeWidth, _ = leftEyeImg.shape\n",
    "            \n",
    "            xLeftEye, yLeftEye, leftEyeWidth, leftEyeHeight = getLeftEyeRect(frame_output, landmarks)\n",
    "            cv2.rectangle(frame_output, (xLeftEye, yLeftEye),\n",
    "                          (xLeftEye + leftEyeWidth, yLeftEye + leftEyeHeight), (200, 21, 36), 2)\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                #drawing irisis\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame_output,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "                )\n",
    "            \n",
    "                # Draw irises\n",
    "                draw_iris(frame_output, face_landmarks.landmark, RIGHT_IRIS, (0, 255, 0))  # Right iris\n",
    "                draw_iris(frame_output, face_landmarks.landmark, LEFT_IRIS, (0, 0, 255))   # Left iris\n",
    "            \n",
    "            \n",
    "                #Gaze detection\n",
    "                image_shape = frame_output.shape\n",
    "\n",
    "                # Get bounding boxes for both eyes\n",
    "                right_eye_bbox = get_eye_bbox(face_landmarks.landmark, RIGHT_EYE, image_shape)\n",
    "                left_eye_bbox = get_eye_bbox(face_landmarks.landmark, LEFT_EYE, image_shape)\n",
    "\n",
    "                # Get iris landmarks\n",
    "                right_iris = [face_landmarks.landmark[i] for i in RIGHT_IRIS]\n",
    "                left_iris = [face_landmarks.landmark[i] for i in LEFT_IRIS]\n",
    "\n",
    "                # Detect gaze for each eye\n",
    "                right_gaze = detect_gaze(right_iris, right_eye_bbox,image_shape)\n",
    "                left_gaze = detect_gaze(left_iris, left_eye_bbox,image_shape)\n",
    "\n",
    "                # Draw bounding boxes and annotate gaze direction\n",
    "                cv2.rectangle(frame_output, (right_eye_bbox[0], right_eye_bbox[1]),\n",
    "                              (right_eye_bbox[0] + right_eye_bbox[2], right_eye_bbox[1] + right_eye_bbox[3]),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.rectangle(frame_output, (left_eye_bbox[0], left_eye_bbox[1]),\n",
    "                              (left_eye_bbox[0] + left_eye_bbox[2], left_eye_bbox[1] + left_eye_bbox[3]),\n",
    "                              (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame_output, f\"Right Eye: {right_gaze}\", (50, 50), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(frame_output, f\"Left Eye: {left_gaze}\", (50, 100), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw face mesh on the frame\n",
    "        #output_frame = drawFaceMesh(frame, results)\n",
    "    \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('MediaPipe FaceMesh', frame_output)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "866413d6-34c2-4e66-858c-2f7220276c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45c5065-6f7d-408d-85c0-fd0c8f0eb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "LEFT_IRIS = [474, 475, 476, 477]\n",
    "\n",
    "def draw_iris(image, landmarks, indices, color):\n",
    "    \"\"\"\n",
    "    Draws circles for iris landmarks on the image.\n",
    "    \"\"\"\n",
    "    image_height, image_width, _ = image.shape\n",
    "    for idx in indices:\n",
    "        x = int(landmarks[idx].x * image_width)\n",
    "        y = int(landmarks[idx].y * image_height)\n",
    "        cv2.circle(image, (x, y), 2, color, -1)  # Draw small circles for the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b35b1ef-8169-4164-a2a0-07e692ce12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drawFaceMesh(image, results):\n",
    "    \"\"\"\n",
    "    Draws face mesh landmarks on the image.\n",
    "    \"\"\"\n",
    "    image.flags.writeable = True\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf3f1c63-7a24-4533-b093-7edcd647a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Iris and eye landmarks\n",
    "RIGHT_EYE = [33, 133, 160, 159, 158, 144, 153, 154, 155]\n",
    "LEFT_EYE = [362, 263, 387, 386, 385, 373, 380, 374, 381]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "LEFT_IRIS = [474, 475, 476, 477]\n",
    "\n",
    "def get_eye_bbox(landmarks, indices, image_shape):\n",
    "    \"\"\"\n",
    "    Get the bounding box of the eye based on landmarks.\n",
    "    \"\"\"\n",
    "    x_coords = [landmarks[i].x * image_shape[1] for i in indices]\n",
    "    y_coords = [landmarks[i].y * image_shape[0] for i in indices]\n",
    "\n",
    "    x_min = int(min(x_coords))\n",
    "    y_min = int(min(y_coords))\n",
    "    x_max = int(max(x_coords))\n",
    "    y_max = int(max(y_coords))\n",
    "\n",
    "    return (x_min, y_min, x_max - x_min, y_max - y_min)  # x, y, width, height\n",
    "\n",
    "def detect_gaze(iris_landmarks, eye_bbox, image_shape):\n",
    "    \"\"\"\n",
    "    Detect gaze direction with more granular descriptions based on iris position.\n",
    "    \"\"\"\n",
    "    # Convert normalized iris landmarks to pixel coordinates\n",
    "    iris_center_x = sum([landmark.x for landmark in iris_landmarks]) / len(iris_landmarks) * image_shape[1]\n",
    "    iris_center_y = sum([landmark.y for landmark in iris_landmarks]) / len(iris_landmarks) * image_shape[0]\n",
    "\n",
    "    # Eye bounding box dimensions\n",
    "    eye_left = eye_bbox[0]\n",
    "    eye_right = eye_bbox[0] + eye_bbox[2]\n",
    "    eye_top = eye_bbox[1]\n",
    "    eye_bottom = eye_bbox[1] + eye_bbox[3]\n",
    "\n",
    "    # Debug bounding box and iris center\n",
    "    #print(f\"Eye BBox: Left={eye_left}, Right={eye_right}, Top={eye_top}, Bottom={eye_bottom}\")\n",
    "    #print(f\"Iris Center (in pixels): X={iris_center_x}, Y={iris_center_y}\")\n",
    "\n",
    "    # Relative position within the eye box\n",
    "    iris_x_relative = (iris_center_x - eye_left) / (eye_right - eye_left)\n",
    "    iris_y_relative = (iris_center_y - eye_top) / (eye_bottom - eye_top)\n",
    "\n",
    "    # Debug relative position\n",
    "    #print(f\"iris_x_relative: {iris_x_relative}, iris_y_relative: {iris_y_relative}\")\n",
    "\n",
    "    # Define thresholds for gaze zones\n",
    "    horizontal_thresholds = [0.4, 0.6]  # Left, center, right\n",
    "    vertical_thresholds = [0.4, 0.6]    # Up, center, down\n",
    "\n",
    "    # Determine horizontal gaze direction\n",
    "    if iris_x_relative < horizontal_thresholds[0]:\n",
    "        horizontal_gaze = \"Left\"\n",
    "    elif iris_x_relative > horizontal_thresholds[1]:\n",
    "        horizontal_gaze = \"Right\"\n",
    "    else:\n",
    "        horizontal_gaze = \"Center\"\n",
    "\n",
    "    # Determine vertical gaze direction\n",
    "    if iris_y_relative < vertical_thresholds[0]:\n",
    "        vertical_gaze = \"Up\"\n",
    "    elif iris_y_relative > vertical_thresholds[1]:\n",
    "        vertical_gaze = \"Down\"\n",
    "    else:\n",
    "        vertical_gaze = \"Center\"\n",
    "\n",
    "    # Combine horizontal and vertical directions for detailed gaze description\n",
    "    if horizontal_gaze == \"Center\" and vertical_gaze == \"Center\":\n",
    "        return \"Looking Straight Ahead\"\n",
    "    elif horizontal_gaze == \"Center\":\n",
    "        return f\"Looking {vertical_gaze}\"\n",
    "    elif vertical_gaze == \"Center\":\n",
    "        return f\"Looking {horizontal_gaze}\"\n",
    "    else:\n",
    "        return f\"Looking {vertical_gaze}-{horizontal_gaze}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdea8b-cd4c-4f6d-a5d0-fd9911d6987d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
